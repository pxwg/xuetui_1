= 学推研究过程记录
<学推研究过程记录>
张乐晗 2025.9.30

= 实地考察
<实地考察>
== 4.17 蔚来汽车中心参访
<蔚来汽车中心参访>
今天是我们项目组第一次真正意义上的实地考察，跟着学校车辆学院科协一起参访了蔚来汽车体验中心。之前看再多资料和视频，都不如亲手摸到方向盘、亲身体验智能驾驶座舱来得真切。我试驾了 NIO
ET9，在真实道路上感受了辅助驾驶系统的运行。和蔚来研发人员的交流也收获很大，他们从技术的角度解释了很多我们之前的困惑。感觉做研究真的要走出来，课本和文献里的知识是平面的，但当你坐在车里，看着系统接管方向盘，那种对“人机关系”的思考才会变得立体起来。

// #box(image("media/image1.png", height: 1.93681in, width: 2.58056in))#box(image("media/image2.png", height: 1.77778in, width: 3.03194in))

== 4.27 长城汽车企业参访
<长城汽车企业参访>
这次跟着学院去了长城汽车的研发技术中心，感觉更“硬核”了。我们参观了研发展厅和实验室，还和智能驾驶专家李秦进行了座谈。他详细讲解了长城 Coffee
Pilot
Ultra 和 Hi4 技术体系，聊了很多技术细节。说实话，很多内容对我来说还比较深奥，但努力听下来，感觉对智能驾驶的“底层逻辑”有了更深的理解。最大的感触是，一个看似简单的功能背后，是无数工程师和复杂的系统在支撑，这让我们对研究这个课题更加心存敬畏。

// #box(image("media/image3.jpeg", height: 1.93611in, width: 3.43889in))

// #box(image("media/image4.png", height: 2.00972in, width: 3.57222in))

== 5.18 六大车企线下门店卧底调研
<六大车企线下门店卧底调研>
今天我们项目组的三个同学装成“准备买车的应届毕业生”，在北京清河万象汇逛了一整天，把小米、理想、华为、智己、极氪的门店都跑遍了。我们深入体验了各家最新的智驾车型，还试驾了好几款。

当一天“消费者”下来，最大的感受是，销售口中宣传的那些天花乱坠的功能，在实际道路上体验起来并没有那么完美。我们也发现，不同车型的摄像头和雷达配置差别很大，这背后可能就隐藏着安全风险。这次调研让我们深刻体会到，从“宣传”到“用户实际体验”之间，还有很长一段路要走，而这正是我们研究可以切入的地方。

// #box(image("media/image5.png", height: 2.87847in, width: 2.15694in))#box(image(
//   "media/image6.png",
//   height: 2.90694in,
//   width: 2.17847in,
// ))#box(image("media/image7.png", height: 3.37708in, width: 2.53125in))#box(
//   image("media/image8.png", height: 3.54097in, width: 2.65417in),
// )#box(image("media/image9.png", height: 1.90694in, width: 2.54375in))
调研过程中拍摄的一些零零碎碎的图片

= 访谈和调研
<访谈和调研>
== 7.2 极星智驾车主访谈
<极星智驾车主访谈>
这是我们第一次正式访谈真实的车主。聊下来感觉特别有价值，很多从用户嘴里说出来的鲜活感受，是我们在报告里看不到的。比如他提到的一些使用习惯和对功能的吐槽，都非常具体。这让我们意识到，不能只从工程师的视角看问题，用户的真实体验和“非理性”的情感，同样是构成“信任”的重要部分。

// #box(image("media/image10.png", height: 6.63611in, width: 5.76319in))

== 7.15-8.15 数据收集和数据分析
<数据收集和数据分析>
正式开始数据分析之前，我们从事故发生到 7 月，我们大量浏览了互联网上各个平台的评论内容，找到了一些讨论最多的话题，并基本找到了讨论最微博、知乎、抖音/快手、汽车之家/懂车帝这几个平台作为数据收集的对象，因为这几个平台的讨论热度很高、平台用户也大多对汽车比较了解。到了 7 月中旬，事故讨论基本已经平息，从 3 月 29 日铜陵小米 SU7 爆燃事故发生开始已经过去了两个月，互联网上的舆论数据非常充分，积累形成了几个热点话题。

我们将互联网上的评论进行了收集和分析，发现基本可以归纳为……几个点。

// #box(image("media/image11.png", height: 7.41319in, width: 5.76667in))

首先，我们整理了互联网上所有评论的角度，并浏览了所有的分析视频和文章，得到了一张较为完善的思维导图

// #box(image("media/image12.jpeg", height: 4.5875in, width: 5.57222in))

我们认为，从设计史角度理解这件事应当聚焦于车企能做的事情，“即使不是车企的错，也有车企的责任”。对于部分认为是驾驶员责任的评论，我们仔细理解其内涵，也可以发现其中对应到的车企责任，比如有很多评论提到车主对智能辅助驾驶的理解有错误造成了滥用，这其实关乎车企应该怎样改进购车之后的安全教育------仅仅靠安全手册，会带来什么问题？因此，比起第一版的分类聚焦于责任划分，我们在第二版并没有特别聚焦于责任本身，而是从探讨问题的维度进行了重新聚类。

接下来，我们的数据分析同样按照这个思路展开，聚焦于具体的分类。

// #box(image("media/image13.png", height: 2.73264in, width: 2.88542in))

// #box(image("media/image14.png", height: 2.69514in, width: 2.38264in))

// #box(image("media/image15.png", height: 1.1875in, width: 2.8125in))
//
// #box(image("media/image16.png", height: 1.57083in, width: 2.60556in))

组内语音沟通

== 8.9 车企工程师访谈
<车企工程师访谈>
针对市面上的智能辅助驾驶汽车所存在的伦理问题，我们邀请一线专家，先后就职于百度智能汽车部门、小鹏汽车数字化产品部门的工程师做了一个很详细的采访。能和产业界的一线专家直接对话，机会真的很难得。我们把数据分析中遇到的困惑，以及对伦理问题的思考都抛给了他，得到了很多实在的反馈。这种感觉很奇妙，像是把我们这些偏理论和设计的思考，放到了真实的产业环境中进行了一次“压力测试”。

// #box(image("media/image17.jpeg", height: 3.46042in, width: 4.61597in))

// #box(image("media/image18.png", height: 0.97014in, width: 5.76042in))

#highlight[插入文档“访谈提纲”]

#highlight[插入文档“8.9 采访核心总结”]

== 8.19 交通工具设计领域专家访谈
<交通工具设计领域专家访谈>
这次联系到了一位交通工具设计领域的专家。这次访谈可以说是我们整个项目的一个转折点。这位教授从智慧出行、人机工程与设计心理学的角度指出，驾驶员在车内睡着等危险行为的根源，在于对智能驾驶系统建立了“过度信任”，这恰恰反映出用户并未真正理解系统的能力边界。因此，专家建议将研究核心从宽泛的“人机协调”聚焦于如何帮助用户建立“适度的初始信任”。

我后来又重新梳理了从开始到现在的研究思路，发现这个聚焦点确实可以为整个项目提供清晰的研究主线，即将安全教育、人机交互等分散的问题，统一收束到“通过设计手段，引导用户在初次接触智能驾驶系统时就形成一个既不过高也不过低的、恰当的信任水平”这一目标上。我们后来复盘时都觉得，感觉整个项目的“灵魂”在那一刻找到了，大家都非常兴奋。

// #box(image("media/image19.png", height: 4.16181in, width: 3.62639in))

== 8.30 特斯拉智驾车主访谈
<特斯拉智驾车主访谈>
这是一个特别信任特斯拉的车主，她表示其智驾功能在高速和环路上使用起来完全没有问题，且非常方便，但这里值得注意的是，她并非盲目信赖技术，而是通过实践，将其应用严格限定在高速、环线等结构化道路上。而且，她并没有购买顶配版的自动驾驶方案，而是在单调通勤中创造处理简单事务（如吃早餐）的“微自由”，从而将“垃圾时间”转化为个人时间。

同时，她在智驾使用过程中对车始终保持高度控制，通过预判系统可能出现的错误并提前干预，展现了典型的人机共同适应行为。她买车已经三年，她的信任并非建立在系统当前完美无缺的表现上，而是源于第一次去门店试驾时印象深刻的体验、对纯视觉技术路线的认同，以及对系统能通过 OTA 持续升级和改进的未来预期。

// #box(image("media/image20.png", height: 2.65694in, width: 3.54306in)) 访谈结束后我终于记得要拍照了

// #box(image("media/image21.png", height: 5.06875in, width: 4.28194in))

== 8.23 组内线下会议（又忘记拍照了）
<组内线下会议又忘记拍照了>
暑假后第一次碰头，大家纷纷交流了暑期各自的项目进展，并详细计划了下一步试驾实验的流程。我们一致认为，可以在学校里招募对智能辅助驾驶系统感兴趣的同学，邀请他们作为被试来驾驶搭载了智能辅助驾驶系统的车辆。

此时，我们认为整个项目研究的核心是信任问题。我们初步选取了“新手小白司机”作为我们的研究对象，所以需要招募有一定驾龄但并不熟悉智驾系统操作的同学，通过民族志实验观察他们在具体情境中与智能驾驶相关系统的交互过程。在会议上，我们预测：大家在初次使用智能驾驶系统后，一定会大幅提升对智能驾驶的信任程度。因为此时是大家首次完整地体验到智能驾驶的功能，它在绝大多数场景都表现很好，对于年轻的司机而言智能驾驶系统也比较好上手，交互不成问题。然而，随着驾驶里程增加，一定会在某次遇到一个特别重大的危险事件（因为这个是小概率事件，什么时候到达这个时机取决于什么时候遇到危险），驾驶者会迅速降低信任程度至低谷。在此次信任危机之后，由于驾驶者变得极为小心谨慎，他一定会逐渐发现系统比想象中还是靠谱很多，但此时已经经历了一次信任危机，所以信任程度不会像初次使用那样激增，而是缓慢增长至一个合理的信任值，最终达到信任校准。

// #box(image("media/image22.jpeg", height: 1.90208in, width: 2.84514in))

事实上，很多安全事故都是在第一阶段信任激增过程中发生的。如果要实现比较好的信任校准，我们是否可以在信任上升过程给予适当干预，不让信任上升过快，不至于在顶点处遭遇一次急剧的信任下降事故？我们设想出一种理想的信任校准模型：从一开始，信任程度就缓慢增长直至无限逼近合理的信任值。这样，就不会因为信任过高而将太多权力交给智驾、导致事故，也不会因为中期信任突然下降而放弃使用智驾。但是，要怎么实现这一点呢？我们觉得，或许可以设计一套车载的安全教育系统，比如在一开始（信任上升期）通过降智版的智驾功能控制信任的上升幅度，并通过实时的操作教育引导驾驶者正确使用智能驾驶。当然，上述这些都是我们的设想，具体的信任变化是不是这样的曲线、每个阶段的变化到底是出于什么原因，都需要进一步思考研究。

我们决定做试驾实验，利用设计人类学的民族志方法，在具体的情境中观察“涌现的问题和驾驶者的即兴反应”。我们组伟大的组员郑皓之同学提出贡献家中的问界 M9，供大家进行试驾实验。于是，这场实验就这样开始了筹划。

#highlight[插入文档“试驾环节执行方案”]

#highlight[插入文档“测试量表”]

== 10.1 一线专家访谈
<一线专家访谈>
// #box(image("media/image23.png", height: 6.04097in, width: 5.75486in))

= 正式的实验环节开始
<正式的实验环节开始>
= 贯穿始终的文献调研
<贯穿始终的文献调研>
